{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Installation**","metadata":{}},{"cell_type":"markdown","source":"# Translating medical terminology for rare diseases used by laypeople into the Human Phenotype Ontology with NLP and the BERT model","metadata":{}},{"cell_type":"markdown","source":"## Package Installation\n\nBelow is the command to install all the required packages for the project.","metadata":{}},{"cell_type":"code","source":"# Installing necessary packages\n!pip install transformers pandas numpy torch scikit-learn keras-preprocessing plotly prettytable","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:22:14.278535Z","iopub.execute_input":"2023-10-01T15:22:14.278871Z","iopub.status.idle":"2023-10-01T15:22:23.615506Z","shell.execute_reply.started":"2023-10-01T15:22:14.278844Z","shell.execute_reply":"2023-10-01T15:22:23.614362Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nCollecting keras-preprocessing\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (5.15.0)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (3.8.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from keras-preprocessing) (1.16.0)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly) (8.2.2)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable) (0.2.6)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nInstalling collected packages: keras-preprocessing\nSuccessfully installed keras-preprocessing-1.1.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing Required Libraries and Packages\n\nBelow are the import statements required for the project.","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries from the transformers package for BERT model\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\n# Importing data manipulation libraries\nimport pandas as pd\nimport numpy as np\n\n# Importing torch for neural network and related operations\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Importing DataLoader and TensorDataset for batching and managing datasets in PyTorch\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Importing loss functions from PyTorch for binary and multi-class classification\nfrom torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n\n# Importing optimization algorithms from PyTorch\nfrom torch.optim import AdamW, SGD\n\n# Importing learning rate scheduler from PyTorch\nfrom torch.optim.lr_scheduler import StepLR\n\n# Importing train-test split function from scikit-learn for splitting datasets\nfrom sklearn.model_selection import train_test_split\n\n# Importing accuracy score from scikit-learn for model evaluation\nfrom sklearn.metrics import accuracy_score\n\n# Importing sequence padding function from Keras preprocessing\nfrom keras_preprocessing.sequence import pad_sequences\n\n# Importing various metrics from scikit-learn for model evaluation\nfrom sklearn.metrics import (\n    precision_recall_fscore_support, \n    hamming_loss, \n    jaccard_score, \n    log_loss, \n    accuracy_score, \n    roc_auc_score\n)\n\n# Importing Plotly's graph objects for data visualization\nimport plotly.graph_objects as go\n\n# Importing PrettyTable for tabular data representation\nfrom prettytable import PrettyTable","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:22:29.872913Z","iopub.execute_input":"2023-10-01T15:22:29.873304Z","iopub.status.idle":"2023-10-01T15:22:43.713562Z","shell.execute_reply.started":"2023-10-01T15:22:29.873247Z","shell.execute_reply":"2023-10-01T15:22:43.712480Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Loading and Preliminary Analysis\n\nWe load a dataset from a specified path, display its dimensions, show a few rows of data, compute and display the maximum sentence length in a specific column, and report the total number of records in the following code snippets. Finally, the text data and labels are separated for further processing.\n\n### Note\nIf running on local or any other machine, please change the file path below.","metadata":{}},{"cell_type":"code","source":"# Load the data from a CSV file\n# The commented line is an alternative path for a different dataset\n# df = pd.read_csv('')\ndf = pd.read_csv('/kaggle/input/r-diseases-dataset/model_input_latest_subset.csv')\n\n# Print the shape of the dataframe to get an understanding of its size\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:22:53.181471Z","iopub.execute_input":"2023-10-01T15:22:53.181889Z","iopub.status.idle":"2023-10-01T15:22:53.231455Z","shell.execute_reply.started":"2023-10-01T15:22:53.181853Z","shell.execute_reply":"2023-10-01T15:22:53.230551Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(1237, 81)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Display the first 5 rows of the data to understand its structure\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:23:08.008677Z","iopub.execute_input":"2023-10-01T15:23:08.009014Z","iopub.status.idle":"2023-10-01T15:23:08.036862Z","shell.execute_reply.started":"2023-10-01T15:23:08.008989Z","shell.execute_reply":"2023-10-01T15:23:08.035840Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                    week_description  HP:0000010  HP:0000012  \\\n0  The dizziness has become more frequent, and it...           0           0   \n1  The muscle twitches are still there, but now I...           0           0   \n2  The muscle twitches are still there, but now I...           0           0   \n3  This week, the tingling sensations in my finge...           0           0   \n4  This week, the tingling sensations in my finge...           0           0   \n\n   HP:0000019  HP:0000211  HP:0000219  HP:0000467  HP:0000522  HP:0000717  \\\n0           0           0           0           0           0           0   \n1           0           0           0           0           0           0   \n2           0           0           0           0           0           0   \n3           0           0           0           0           0           0   \n4           0           0           0           0           0           0   \n\n   HP:0000756  ...  HP:0030237  HP:0030319  HP:0031744  HP:0032365  \\\n0           0  ...           0           0           0           0   \n1           0  ...           0           0           0           0   \n2           0  ...           0           0           0           0   \n3           0  ...           0           0           0           0   \n4           0  ...           0           0           0           0   \n\n   HP:0033679  HP:0040282  HP:0040283  HP:0100524  HP:0100759  HP:0100852  \n0           0           0           0           0           0           0  \n1           0           0           1           0           0           0  \n2           0           1           0           0           0           0  \n3           0           0           1           0           0           0  \n4           0           1           0           0           0           0  \n\n[5 rows x 81 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>week_description</th>\n      <th>HP:0000010</th>\n      <th>HP:0000012</th>\n      <th>HP:0000019</th>\n      <th>HP:0000211</th>\n      <th>HP:0000219</th>\n      <th>HP:0000467</th>\n      <th>HP:0000522</th>\n      <th>HP:0000717</th>\n      <th>HP:0000756</th>\n      <th>...</th>\n      <th>HP:0030237</th>\n      <th>HP:0030319</th>\n      <th>HP:0031744</th>\n      <th>HP:0032365</th>\n      <th>HP:0033679</th>\n      <th>HP:0040282</th>\n      <th>HP:0040283</th>\n      <th>HP:0100524</th>\n      <th>HP:0100759</th>\n      <th>HP:0100852</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The dizziness has become more frequent, and it...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The muscle twitches are still there, but now I...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The muscle twitches are still there, but now I...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This week, the tingling sensations in my finge...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This week, the tingling sensations in my finge...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 81 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize a variable to keep track of the maximum sentence length\nmax_sentence_length = 0\n\n# Iterate through each record in the dataset\nfor index, row in df.iterrows():\n    # Extract the week description from the current record\n    week_description = row['week_description']\n    \n    # Compute the length of the sentence by splitting it into words\n    sentence_length = len(week_description.split())\n    \n    # Update the maximum sentence length if the current sentence is longer\n    max_sentence_length = max(max_sentence_length, sentence_length)\n\n# Print the maximum sentence length\nprint(f\"Maximum sentence length: {max_sentence_length}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:23:13.411882Z","iopub.execute_input":"2023-10-01T15:23:13.412208Z","iopub.status.idle":"2023-10-01T15:23:13.472165Z","shell.execute_reply.started":"2023-10-01T15:23:13.412182Z","shell.execute_reply":"2023-10-01T15:23:13.471199Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Maximum sentence length: 89\n","output_type":"stream"}]},{"cell_type":"code","source":"# Report the total number of records in the dataset\nprint('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n\n# Separate the text data and labels for further processing\n# Extract the 'week_description' column as the text data\ntexts = df['week_description'].values\n\n# Drop the 'week_description' column and use the remaining columns as labels\nlabels = df.drop('week_description', axis=1).values","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:23:23.101097Z","iopub.execute_input":"2023-10-01T15:23:23.101456Z","iopub.status.idle":"2023-10-01T15:23:23.110284Z","shell.execute_reply.started":"2023-10-01T15:23:23.101425Z","shell.execute_reply":"2023-10-01T15:23:23.109383Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of training sentences: 1,237\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Text Tokenization and Input Preparation\n\nIn this part of the code, we focus on preparing our text data for the BERT model by tokenizing the text, padding and truncating the token sequences, and creating attention masks to indicate which tokens are meaningful and which are padding.","metadata":{}},{"cell_type":"code","source":"# Instantiate a BERT tokenizer to convert text to token IDs\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Step 1: Tokenize Text\n# Tokenize the text data, adding the special tokens [CLS] and [SEP] as required by BERT\ninput_ids = [tokenizer.encode(text, add_special_tokens=True) for text in texts]\n\n# Step 2: Padding and Truncating\n# Ensure that all sequences are of the same length by padding and truncating\n# We choose a maximum length of 128 tokens for this purpose\ninput_ids = pad_sequences(\n    input_ids, \n    maxlen=128, \n    dtype=\"long\", \n    value=0,  # Value used for padding\n    truncating=\"post\",  # Truncate sequences from the end if necessary\n    padding=\"post\"  # Pad sequences at the end if necessary\n)\n\n# Step 3: Create Attention Masks\n# Create attention masks to differentiate actual tokens from padding\n# A mask value of 1 indicates a real token, while a value of 0 indicates padding\nattention_masks = []\nfor seq in input_ids:\n    # Create a mask for the current sequence\n    seq_mask = [float(i > 0) for i in seq]  # i > 0 checks whether the token ID is not padding (0)\n    attention_masks.append(seq_mask)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:23:30.304936Z","iopub.execute_input":"2023-10-01T15:23:30.305277Z","iopub.status.idle":"2023-10-01T15:23:32.961549Z","shell.execute_reply.started":"2023-10-01T15:23:30.305249Z","shell.execute_reply":"2023-10-01T15:23:32.960501Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53a0b6df48c64e8594c77bf996c80ca0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcde21b84ac649a5a1229b6dc26fc03f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5694be2363c34f2c8c0b177271c8127b"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Splitting and DataLoader Preparation\n\nIn this section, we split the input data and labels into training, validation, and test sets to prepare them for model training, validation, and testing. Additionally, we convert the data into PyTorch tensors and organize them into DataLoaders for efficient batch processing during training and evaluation.","metadata":{}},{"cell_type":"code","source":"# Step 1: Splitting the Data\n# Split the input data and labels into training and temporary sets (for further splitting)\ntrain_inputs, temp_inputs, train_labels, temp_labels = train_test_split(\n    input_ids, labels, \n    random_state=42,  # Ensures reproducibility\n    test_size=0.2  # Specifies the proportion of the data to include in the test set\n)\n\n# Split the temporary sets into validation and test sets\nval_inputs, test_inputs, val_labels, test_labels = train_test_split(\n    temp_inputs, temp_labels, \n    random_state=42,  # Ensures reproducibility\n    test_size=0.5  # Specifies the proportion of the data to include in the test set\n)\n\n# Also split the attention masks in a similar fashion\ntrain_masks, temp_masks, _, _ = train_test_split(attention_masks, labels, random_state=42, test_size=0.2)\nval_masks, test_masks, _, _ = train_test_split(temp_masks, temp_labels, random_state=42, test_size=0.5)\n\n# Step 2: Converting Data to PyTorch Tensors\n# Convert all inputs, masks, and labels to PyTorch tensors as required for training in PyTorch\ntrain_inputs = torch.tensor(train_inputs)\nval_inputs = torch.tensor(val_inputs)\ntest_inputs = torch.tensor(test_inputs)\n\ntrain_masks = torch.tensor(train_masks)\nval_masks = torch.tensor(val_masks)\ntest_masks = torch.tensor(test_masks)\n\ntrain_labels = torch.tensor(train_labels)\nval_labels = torch.tensor(val_labels)\ntest_labels = torch.tensor(test_labels)\n\n# Step 3: Creating DataLoaders\n# Organize the data into DataLoaders for efficient batch processing during training and evaluation\n# Set the batch size to 32\nbatch_size = 32\n\n# Create DataLoader for the training set\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_dataloader = DataLoader(train_data, batch_size=batch_size)\n\n# Create DataLoader for the validation set\nval_data = TensorDataset(val_inputs, val_masks, val_labels)\nval_dataloader = DataLoader(val_data, batch_size=batch_size)\n\n# Create DataLoader for the test set\ntest_data = TensorDataset(test_inputs, test_masks, test_labels)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:23:38.237811Z","iopub.execute_input":"2023-10-01T15:23:38.238252Z","iopub.status.idle":"2023-10-01T15:23:38.342763Z","shell.execute_reply.started":"2023-10-01T15:23:38.238213Z","shell.execute_reply":"2023-10-01T15:23:38.341730Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Model Initialization and Device Preparation\n\nIn this section, we initialize the BERT model for sequence classification and a linear classifier. We also prepare the computing device (CPU or GPU) for training and evaluation.","metadata":{}},{"cell_type":"code","source":"# Step 1: Initialize BERT Model\n# Initialize a BERT model for sequence classification with the required number of output labels\n# We use the 'bert-base-uncased' pre-trained model as a starting point\nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\", \n    num_labels=train_labels.shape[1]  # The number of output labels equals the number of columns in train_labels\n)\n\n# Step 2: Initialize Linear Classifier\n# Initialize a linear classifier to be trained alongside the BERT model\n# The input and output dimensions are both equal to the number of labels\nclassifier = torch.nn.Linear(\n    train_labels.shape[1], \n    train_labels.shape[1]\n)\n\n# Step 3: Prepare Computing Device\n# Determine the computing device (CPU or GPU) and send the model and classifier to this device\ndevice = torch.device(\n    \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU (cuda) if available, otherwise fall back to CPU\n)\n\n# Send the model and classifier to the chosen device\nmodel.to(device)\nclassifier.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:23:44.632100Z","iopub.execute_input":"2023-10-01T15:23:44.632579Z","iopub.status.idle":"2023-10-01T15:23:54.627253Z","shell.execute_reply.started":"2023-10-01T15:23:44.632539Z","shell.execute_reply":"2023-10-01T15:23:54.626330Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f59aa139e9c496cac4c7e7ccee0563a"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Linear(in_features=80, out_features=80, bias=True)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Calculating Class Weights\n\nIn this section, we calculate the class weights which are useful to handle imbalanced datasets during training.","metadata":{}},{"cell_type":"code","source":"# Step 1: Count Positive and Negative Samples\n# Count the number of positive samples for each label by summing up the training labels along the column axis\nn_pos = train_labels.sum(axis=0)\n# Uncomment the line below to print the count of positive samples for debugging\n# print(n_pos)\n\n# Calculate the number of negative samples for each label by subtracting the count of positive samples from the total count\nn_neg = len(train_labels) - n_pos\n# Uncomment the line below to print the count of negative samples for debugging\n# print(n_neg)\n\n# Step 2: Calculate Positive Class Weights\n# The positive class weights are calculated as the ratio of negative samples to positive samples for each label\n# Adding a small constant (1e-5) to avoid division by zero\npos_weights = (n_neg + 1e-5) / (n_pos + 1e-5)\n\n# Uncomment the line below to print the calculated positive class weights for debugging\n# print(f\"Positive Weights: {pos_weights}\")\n\n# Step 3: Convert to Tensor and Send to Device\n# Convert the numpy array of positive class weights to a PyTorch tensor\n# Then send the tensor to the chosen computing device (CPU or GPU)\npos_weights = torch.tensor(pos_weights).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:24:00.342475Z","iopub.execute_input":"2023-10-01T15:24:00.343056Z","iopub.status.idle":"2023-10-01T15:24:00.362119Z","shell.execute_reply.started":"2023-10-01T15:24:00.343024Z","shell.execute_reply":"2023-10-01T15:24:00.361075Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_69/1551397999.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  pos_weights = torch.tensor(pos_weights).to(device)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Optimizer, Learning Rate Scheduler, and Loss Function Initialization\n\nIn this section, we initialize the optimizer, learning rate scheduler, and the loss function which are essential components for training the neural network.","metadata":{}},{"cell_type":"code","source":"# Step 1: Initialize Optimizer\n# We use the AdamW optimizer which is an extension of Adam optimized for training deep neural networks\n# We include the parameters of both the BERT model and the linear classifier in the optimizer\noptimizer = AdamW(\n    list(model.parameters()) + list(classifier.parameters()),  # Combine the parameters of model and classifier\n    lr=0.0001  # Set the learning rate\n)\n\n# Step 2: Initialize Learning Rate Scheduler\n# The StepLR scheduler adjusts the learning rate at regular intervals for better convergence\nscheduler = StepLR(\n    optimizer, \n    step_size=10,  # Decrease the learning rate every 10 epochs\n    gamma=0.7  # Multiplicative factor to decrease the learning rate\n)\n\n# Step 3: Initialize Loss Function\n# The pos_weight argument helps handle imbalanced datasets by scaling the loss for positive samples\ncriterion = BCEWithLogitsLoss(\n    pos_weight=pos_weights  # Set the positive weights to handle class imbalance\n)\n\n# Alternative Loss Function\n# The Focal Loss is another alternative for handling imbalanced datasets\n# Uncomment the following lines to use Focal Loss instead of BCEWithLogitsLoss\n# criterion = FocalLoss(\n#     alpha=1, \n#     gamma=2, \n#     logits=True, \n#     reduce=True\n# )\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:24:04.772935Z","iopub.execute_input":"2023-10-01T15:24:04.773266Z","iopub.status.idle":"2023-10-01T15:24:04.779413Z","shell.execute_reply.started":"2023-10-01T15:24:04.773240Z","shell.execute_reply":"2023-10-01T15:24:04.778451Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Definition of Focal Loss\n\nIn this section, we define a custom loss function known as Focal Loss.","metadata":{}},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n        \"\"\"\n        Constructor for the FocalLoss module.\n        :param alpha: (float) Scaling factor for positive class.\n        :param gamma: (float) Focusing parameter to down-weight easy examples.\n        :param logits: (bool) Flag to indicate whether inputs are logits.\n        :param reduce: (bool) Flag to indicate whether to reduce loss to a scalar.\n        \"\"\"\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha  # Scaling factor for the positive class\n        self.gamma = gamma  # Focusing parameter\n        self.logits = logits  # Indicates if the inputs are logits\n        self.reduce = reduce  # Indicates if we should reduce loss to a scalar\n\n    def forward(self, inputs, targets):\n        \"\"\"\n        Forward pass of the FocalLoss module.\n        :param inputs: (tensor) The input logits.\n        :param targets: (tensor) The ground truth labels.\n        :return: (tensor) The computed Focal Loss value.\n        \"\"\"\n        # Compute binary cross-entropy loss\n        # If logits flag is set, use binary cross-entropy with logits, else use regular binary cross-entropy\n        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False) if self.logits else F.binary_cross_entropy(inputs, targets, reduce=False)\n        \n        pt = torch.exp(-BCE_loss)  # Convert BCE loss values to probabilities\n        F_loss = self.alpha * (1 - pt)**self.gamma * BCE_loss  # Compute Focal Loss\n        \n        return torch.mean(F_loss) if self.reduce else F_loss\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utility Functions for Printing Metrics\n\nIn this section, we introduce two utility functions for pretty-printing the metrics during training and evaluation.","metadata":{}},{"cell_type":"code","source":"def pretty_print_metrics(title, metrics):\n    \"\"\"\n    Prints the metrics in a tabular format.\n    \n    :param title: (str) Title to be displayed above the table.\n    :param metrics: (dict) Dictionary containing metric names as keys and their values.\n    \"\"\"\n    \n    # Display the title for the metrics\n    print(f\"\\n{title}\")\n    \n    # Initialize the table\n    table = PrettyTable()\n    \n    # Set the column names for the table\n    table.field_names = [\"Metric\", \"Value\"]\n    \n    # Add rows to the table using metrics data\n    for metric, value in metrics.items():\n        table.add_row([metric, f\"{value:.4f}\"])\n    \n    # Print the table\n    print(table)\n\ndef pretty_print_epoch(epoch, train_loss, val_loss):\n    \"\"\"\n    Prints the training and validation loss for each epoch in a tabular format.\n    \n    :param epoch: (int) Current epoch number.\n    :param train_loss: (float) Training loss for the current epoch.\n    :param val_loss: (float) Validation loss for the current epoch.\n    \"\"\"\n    \n    # Display epoch information\n    print(f\"\\n{'='*40}\")\n    print(f\"Epoch {epoch}\")\n    print(f\"{'='*40}\")\n    \n    # Initialize the table\n    table = PrettyTable()\n    \n    # Set the column names for the table\n    table.field_names = [\"Data Type\", \"Loss\"]\n    \n    # Add rows to the table for training and validation data\n    table.add_row([\"Training\", f\"{train_loss:.4f}\"])\n    table.add_row([\"Validation\", f\"{val_loss:.4f}\"])\n    \n    # Print the table\n    print(table)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:24:16.583101Z","iopub.execute_input":"2023-10-01T15:24:16.583479Z","iopub.status.idle":"2023-10-01T15:24:16.590760Z","shell.execute_reply.started":"2023-10-01T15:24:16.583433Z","shell.execute_reply":"2023-10-01T15:24:16.589868Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Updating Label Data Types\n\nIn this section, we are updating the data types of the label tensors to torch.float32. This data type conversion is essential for ensuring compatibility with PyTorch operations, when using loss functions like BCEWithLogitsLoss.","metadata":{}},{"cell_type":"code","source":"# Converting the data type of training labels to float32\ntrain_labels = torch.tensor(train_labels, dtype=torch.float32)\n\n# Converting the data type of validation labels to float32\nval_labels = torch.tensor(val_labels, dtype=torch.float32)\n\n# Converting the data type of testing labels to float32\ntest_labels = torch.tensor(test_labels, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:24:22.264678Z","iopub.execute_input":"2023-10-01T15:24:22.265022Z","iopub.status.idle":"2023-10-01T15:24:22.271489Z","shell.execute_reply.started":"2023-10-01T15:24:22.264995Z","shell.execute_reply":"2023-10-01T15:24:22.270327Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_69/3817560295.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  train_labels = torch.tensor(train_labels, dtype=torch.float32)\n/tmp/ipykernel_69/3817560295.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  val_labels = torch.tensor(val_labels, dtype=torch.float32)\n/tmp/ipykernel_69/3817560295.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  test_labels = torch.tensor(test_labels, dtype=torch.float32)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training and Validation Loop\n\nIn this section, we set up and run the training and validation loop. We initialize arrays to keep track of training and validation losses over the epochs. In each epoch, we perform a forward and backward pass on the training data, update the model parameters, and compute the average training loss. Then, we evaluate the model on the validation set, compute the average validation loss, and evaluate several performance metrics.","metadata":{}},{"cell_type":"code","source":"# Arrays to store training and validation loss values across epochs\ntrain_loss_values = []\nval_loss_values = []\n\n# Training loop across epochs\nfor epoch in range(16):\n    model.train()  # Set model to training mode\n    \n    avg_train_loss = 0  # Initialize average training loss for the epoch\n    avg_val_loss = 0  # Initialize average validation loss for the epoch\n    \n    # Loop over batches of training data\n    for i, batch in enumerate(train_dataloader):\n        \n        # Send input data and labels to the device\n        inputs, masks, labels = tuple(t.to(device) for t in batch)\n        \n        # Ensure labels are float for loss computation\n        labels = labels.float()\n\n        # Forward pass: compute predictions\n        outputs = model(inputs, attention_mask=masks)\n        logits_from_model = outputs.logits\n        logits = classifier(logits_from_model)\n        \n        # Compute loss\n        loss = criterion(logits, labels)\n        \n        # Perform backward pass to compute gradients\n        loss.backward()\n        \n        # Gradient clipping to prevent exploding gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        \n        # Update model parameters\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        # Update average training loss\n        avg_train_loss += loss.item() / len(train_dataloader)\n        \n        # Print training loss every 100 batches\n        if i % 100 == 0:\n            print(f\"Epoch: {epoch}, Batch: {i}, Training Loss: {loss.item()}\")\n        \n    # Store average training loss for the epoch\n    train_loss_values.append(avg_train_loss)\n\n    # Validation: Evaluate model on validation data\n    model.eval()  # Set model to evaluation mode\n    val_preds = []\n    val_true = []\n    with torch.no_grad():  # No gradient computation\n        for batch in val_dataloader:\n            \n            # Send input data and labels to the device\n            inputs, masks, labels = tuple(t.to(device) for t in batch)\n            \n            # Forward pass: compute predictions\n            outputs = model(inputs, attention_mask=masks)\n            logits_from_model = outputs.logits\n            logits = classifier(logits_from_model)\n            \n            # Store predictions and true labels for later evaluation\n            preds = torch.sigmoid(logits).cpu().numpy()\n            val_preds.extend(preds)\n            val_true.extend(labels.cpu().numpy())\n            \n            # Update average validation loss\n            avg_val_loss += loss.item() / len(val_dataloader)\n        val_loss_values.append(avg_val_loss)\n\n    # Convert prediction probabilities to binary predictions\n    val_preds = np.array(val_preds) >= 0.7\n    val_true = np.array(val_true)\n    \n    # Compute validation accuracy\n    val_accuracy = accuracy_score(val_true, val_preds)\n    \n    # Print summary for the epoch\n    pretty_print_epoch(epoch, avg_train_loss, avg_val_loss)\n    \n    # Compute and print several performance metrics on validation data\n    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(val_true, val_preds, average='micro')\n    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(val_true, val_preds, average='macro')\n    hamming = hamming_loss(val_true, val_preds)\n    jaccard = jaccard_score(val_true, val_preds, average='samples')\n    logloss = log_loss(val_true, val_preds)\n    \n    val_metrics = {\n        'Validation Accuracy': val_accuracy,\n        'Micro-average Precision': precision_micro,\n        'Micro-average Recall': recall_micro,\n        'Micro-average F1': f1_micro,\n        'Macro-average Precision': precision_macro,\n        'Macro-average Recall': recall_macro,\n        'Macro-average F1': f1_macro,\n        'Hamming Loss': hamming,\n        'Jaccard Similarity': jaccard,\n        'Log Loss': logloss\n    }\n\n    pretty_print_metrics('Validation Metrics', val_metrics)  # Use PrettyTable to print validation metrics\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T15:24:27.813456Z","iopub.execute_input":"2023-10-01T15:24:27.813806Z","iopub.status.idle":"2023-10-01T15:27:35.340413Z","shell.execute_reply.started":"2023-10-01T15:24:27.813778Z","shell.execute_reply":"2023-10-01T15:27:35.339504Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch: 0, Batch: 0, Training Loss: 1.3420305252075195\n\n========================================\nEpoch 0\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 1.3238 |\n| Validation | 1.1733 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+---------+\n|          Metric         |  Value  |\n+-------------------------+---------+\n|   Validation Accuracy   |  0.0242 |\n| Micro-average Precision |  0.0852 |\n|   Micro-average Recall  |  0.1210 |\n|     Micro-average F1    |  0.1000 |\n| Macro-average Precision |  0.0327 |\n|   Macro-average Recall  |  0.0802 |\n|     Macro-average F1    |  0.0337 |\n|       Hamming Loss      |  0.0272 |\n|    Jaccard Similarity   |  0.0612 |\n|         Log Loss        | 17.3227 |\n+-------------------------+---------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Batch: 0, Training Loss: 1.172568678855896\n\n========================================\nEpoch 1\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 1.0910 |\n| Validation | 0.9795 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.0484 |\n| Micro-average Precision | 0.0959 |\n|   Micro-average Recall  | 0.8065 |\n|     Micro-average F1    | 0.1714 |\n| Macro-average Precision | 0.1553 |\n|   Macro-average Recall  | 0.5992 |\n|     Macro-average F1    | 0.2059 |\n|       Hamming Loss      | 0.0975 |\n|    Jaccard Similarity   | 0.1709 |\n|         Log Loss        | 7.8362 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Batch: 0, Training Loss: 0.9479204416275024\n\n========================================\nEpoch 2\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.9164 |\n| Validation | 0.8335 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.0323 |\n| Micro-average Precision | 0.1051 |\n|   Micro-average Recall  | 0.9113 |\n|     Micro-average F1    | 0.1885 |\n| Macro-average Precision | 0.1698 |\n|   Macro-average Recall  | 0.6596 |\n|     Macro-average F1    | 0.2382 |\n|       Hamming Loss      | 0.0981 |\n|    Jaccard Similarity   | 0.1712 |\n|         Log Loss        | 4.8578 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Batch: 0, Training Loss: 0.8092786073684692\n\n========================================\nEpoch 3\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.7836 |\n| Validation | 0.7078 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.0565 |\n| Micro-average Precision | 0.1380 |\n|   Micro-average Recall  | 0.9194 |\n|     Micro-average F1    | 0.2400 |\n| Macro-average Precision | 0.2421 |\n|   Macro-average Recall  | 0.6637 |\n|     Macro-average F1    | 0.3074 |\n|       Hamming Loss      | 0.0728 |\n|    Jaccard Similarity   | 0.2317 |\n|         Log Loss        | 4.5575 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Batch: 0, Training Loss: 0.6726325750350952\n\n========================================\nEpoch 4\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.6576 |\n| Validation | 0.5940 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.0887 |\n| Micro-average Precision | 0.1729 |\n|   Micro-average Recall  | 0.9274 |\n|     Micro-average F1    | 0.2915 |\n| Macro-average Precision | 0.2621 |\n|   Macro-average Recall  | 0.6762 |\n|     Macro-average F1    | 0.3265 |\n|       Hamming Loss      | 0.0564 |\n|    Jaccard Similarity   | 0.2895 |\n|         Log Loss        | 3.7857 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Batch: 0, Training Loss: 0.5445205569267273\n\n========================================\nEpoch 5\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.5415 |\n| Validation | 0.4781 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.2500 |\n| Micro-average Precision | 0.2457 |\n|   Micro-average Recall  | 0.9194 |\n|     Micro-average F1    | 0.3878 |\n| Macro-average Precision | 0.3241 |\n|   Macro-average Recall  | 0.6621 |\n|     Macro-average F1    | 0.3883 |\n|       Hamming Loss      | 0.0363 |\n|    Jaccard Similarity   | 0.4275 |\n|         Log Loss        | 3.9316 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Batch: 0, Training Loss: 0.4461219310760498\n\n========================================\nEpoch 6\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.4501 |\n| Validation | 0.4025 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.3468 |\n| Micro-average Precision | 0.2687 |\n|   Micro-average Recall  | 0.9274 |\n|     Micro-average F1    | 0.4167 |\n| Macro-average Precision | 0.3466 |\n|   Macro-average Recall  | 0.6762 |\n|     Macro-average F1    | 0.4098 |\n|       Hamming Loss      | 0.0325 |\n|    Jaccard Similarity   | 0.4962 |\n|         Log Loss        | 3.0011 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 7, Batch: 0, Training Loss: 0.3676368296146393\n\n========================================\nEpoch 7\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.3757 |\n| Validation | 0.3243 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.3387 |\n| Micro-average Precision | 0.3018 |\n|   Micro-average Recall  | 0.9274 |\n|     Micro-average F1    | 0.4554 |\n| Macro-average Precision | 0.3543 |\n|   Macro-average Recall  | 0.6746 |\n|     Macro-average F1    | 0.4190 |\n|       Hamming Loss      | 0.0277 |\n|    Jaccard Similarity   | 0.5077 |\n|         Log Loss        | 2.6842 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 8, Batch: 0, Training Loss: 0.2997286915779114\n\n========================================\nEpoch 8\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.3192 |\n| Validation | 0.2775 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.4113 |\n| Micro-average Precision | 0.3574 |\n|   Micro-average Recall  | 0.9194 |\n|     Micro-average F1    | 0.5147 |\n| Macro-average Precision | 0.4138 |\n|   Macro-average Recall  | 0.6621 |\n|     Macro-average F1    | 0.4669 |\n|       Hamming Loss      | 0.0217 |\n|    Jaccard Similarity   | 0.5648 |\n|         Log Loss        | 2.8326 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 9, Batch: 0, Training Loss: 0.2542976140975952\n\n========================================\nEpoch 9\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.2748 |\n| Validation | 0.2435 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.4435 |\n| Micro-average Precision | 0.3750 |\n|   Micro-average Recall  | 0.9194 |\n|     Micro-average F1    | 0.5327 |\n| Macro-average Precision | 0.4334 |\n|   Macro-average Recall  | 0.6621 |\n|     Macro-average F1    | 0.4828 |\n|       Hamming Loss      | 0.0202 |\n|    Jaccard Similarity   | 0.5911 |\n|         Log Loss        | 2.7826 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10, Batch: 0, Training Loss: 0.21940842270851135\n\n========================================\nEpoch 10\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.2400 |\n| Validation | 0.2116 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.4677 |\n| Micro-average Precision | 0.3966 |\n|   Micro-average Recall  | 0.9274 |\n|     Micro-average F1    | 0.5556 |\n| Macro-average Precision | 0.4580 |\n|   Macro-average Recall  | 0.6663 |\n|     Macro-average F1    | 0.5034 |\n|       Hamming Loss      | 0.0185 |\n|    Jaccard Similarity   | 0.6137 |\n|         Log Loss        | 2.4529 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 11, Batch: 0, Training Loss: 0.1919858604669571\n\n========================================\nEpoch 11\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.2103 |\n| Validation | 0.1848 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.4839 |\n| Micro-average Precision | 0.4107 |\n|   Micro-average Recall  | 0.9274 |\n|     Micro-average F1    | 0.5693 |\n| Macro-average Precision | 0.4808 |\n|   Macro-average Recall  | 0.6746 |\n|     Macro-average F1    | 0.5225 |\n|       Hamming Loss      | 0.0175 |\n|    Jaccard Similarity   | 0.6239 |\n|         Log Loss        | 2.4280 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 12, Batch: 0, Training Loss: 0.17076902091503143\n\n========================================\nEpoch 12\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.1883 |\n| Validation | 0.1634 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.5000 |\n| Micro-average Precision | 0.4238 |\n|   Micro-average Recall  | 0.9194 |\n|     Micro-average F1    | 0.5802 |\n| Macro-average Precision | 0.4684 |\n|   Macro-average Recall  | 0.6621 |\n|     Macro-average F1    | 0.5114 |\n|       Hamming Loss      | 0.0166 |\n|    Jaccard Similarity   | 0.6378 |\n|         Log Loss        | 2.6833 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 13, Batch: 0, Training Loss: 0.14972208440303802\n\n========================================\nEpoch 13\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.1699 |\n| Validation | 0.1519 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.4839 |\n| Micro-average Precision | 0.4302 |\n|   Micro-average Recall  | 0.9194 |\n|     Micro-average F1    | 0.5861 |\n| Macro-average Precision | 0.4774 |\n|   Macro-average Recall  | 0.6621 |\n|     Macro-average F1    | 0.5161 |\n|       Hamming Loss      | 0.0162 |\n|    Jaccard Similarity   | 0.6306 |\n|         Log Loss        | 2.6795 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 14, Batch: 0, Training Loss: 0.13372908532619476\n\n========================================\nEpoch 14\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.1573 |\n| Validation | 0.1386 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.4758 |\n| Micro-average Precision | 0.4101 |\n|   Micro-average Recall  | 0.9194 |\n|     Micro-average F1    | 0.5672 |\n| Macro-average Precision | 0.4705 |\n|   Macro-average Recall  | 0.6621 |\n|     Macro-average F1    | 0.5110 |\n|       Hamming Loss      | 0.0175 |\n|    Jaccard Similarity   | 0.6195 |\n|         Log Loss        | 2.7120 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 15, Batch: 0, Training Loss: 0.12760165333747864\n\n========================================\nEpoch 15\n========================================\n+------------+--------+\n| Data Type  |  Loss  |\n+------------+--------+\n|  Training  | 0.1458 |\n| Validation | 0.1300 |\n+------------+--------+\n\nValidation Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|   Validation Accuracy   | 0.4839 |\n| Micro-average Precision | 0.4330 |\n|   Micro-average Recall  | 0.9113 |\n|     Micro-average F1    | 0.5870 |\n| Macro-average Precision | 0.4815 |\n|   Macro-average Recall  | 0.6517 |\n|     Macro-average F1    | 0.5140 |\n|       Hamming Loss      | 0.0160 |\n|    Jaccard Similarity   | 0.6329 |\n|         Log Loss        | 3.2193 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluation on Test Set\n\nThis section presents the evaluation of the model on the test set. The model's performance is assessed across various metrics including loss, accuracy, precision, recall, F1-score, Hamming Loss, Jaccard Similarity, and Log Loss. The evaluation is carried out batch-wise, and the predictions along with labels are stored for metric computation.","metadata":{}},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to keep track of total loss and correct predictions\ntotal_loss = 0\ntotal_correct = 0\n\n# Lists to store all predictions and labels\nall_preds = []\nall_labels = []\n\n# Loop over batches in the test dataloader\nfor i, batch in enumerate(test_dataloader):\n    \n    # Unpack the batch and move tensors to the appropriate device\n    inputs, masks, labels = tuple(t.to(device) for t in batch)\n    \n    # Ensure labels are float for loss computation\n    labels = labels.float()\n    \n    # No gradient computation in evaluation phase\n    with torch.no_grad():\n        # Forward pass: Compute predictions\n        outputs = model(inputs, attention_mask=masks)\n        logits_from_model = outputs.logits\n        logits = classifier(logits_from_model)\n        \n        # Compute loss\n        loss = criterion(logits, labels)\n        \n        # Accumulate loss\n        total_loss += loss.item()\n        \n        # Convert logits to probabilities and store predictions and labels\n        preds = torch.sigmoid(logits).cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels.cpu().numpy())\n\n# Convert list of predictions and labels to NumPy arrays for easier manipulation\nall_preds_np = np.array(all_preds)\nall_labels_np = np.array(all_labels)\n\n# Binarize predictions based on threshold\nbinary_preds = all_preds_np >= 0.7\n\n# Calculate Metrics\nprecision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(all_labels_np, binary_preds, average='micro')\nprecision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels_np, binary_preds, average='macro')\nhamming = hamming_loss(all_labels_np, binary_preds)\njaccard = jaccard_score(all_labels_np, binary_preds, average='samples')\nlogloss = log_loss(all_labels_np, all_preds_np)\naccuracy = accuracy_score(all_labels_np, binary_preds)\n\n# Organize metrics in a dictionary and print using pretty_print_metrics function\ntest_metrics = {\n    'Test Loss': total_loss / len(test_dataloader),\n    'Test Accuracy': accuracy,\n    'Micro-Average Precision': precision_micro,\n    'Micro-Average Recall': recall_micro,\n    'Micro-Average F1-score': f1_micro,\n    'Macro-Average Precision': precision_macro,\n    'Macro-Average Recall': recall_macro,\n    'Macro-Average F1-score': f1_macro,\n    'Hamming Loss': hamming,\n    'Jaccard Similarity': jaccard,\n    'Log Loss': logloss\n}\n\n# Use PrettyTable to display test metrics\npretty_print_metrics('Test Metrics', test_metrics)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:29:40.727505Z","iopub.execute_input":"2023-10-01T15:29:40.727872Z","iopub.status.idle":"2023-10-01T15:29:41.217913Z","shell.execute_reply.started":"2023-10-01T15:29:40.727844Z","shell.execute_reply":"2023-10-01T15:29:41.217002Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nTest Metrics\n+-------------------------+--------+\n|          Metric         | Value  |\n+-------------------------+--------+\n|        Test Loss        | 0.3620 |\n|      Test Accuracy      | 0.4274 |\n| Micro-Average Precision | 0.4264 |\n|   Micro-Average Recall  | 0.9113 |\n|  Micro-Average F1-score | 0.5810 |\n| Macro-Average Precision | 0.5084 |\n|   Macro-Average Recall  | 0.7271 |\n|  Macro-Average F1-score | 0.5557 |\n|       Hamming Loss      | 0.0164 |\n|    Jaccard Similarity   | 0.6036 |\n|         Log Loss        | 2.0545 |\n+-------------------------+--------+\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Plotting Training and Validation Loss\n\nIn this section, we use Plotly to create a plot that depicts the training and validation loss over epochs. Each point on the plot represents the loss at the end of an epoch, for both training and validation phases. This visualization helps in understanding how the model is learning and whether it's overfitting (if the validation loss starts increasing).","metadata":{}},{"cell_type":"code","source":"# Create a figure using Plotly's go.Figure()\nfig = go.Figure()\n\n# Add a trace for training loss values over epochs\nfig.add_trace(\n    go.Scatter(\n        x=list(range(len(train_loss_values))),  # X-axis: Epoch number\n        y=train_loss_values,  # Y-axis: Training loss value\n        mode='lines+markers',  # Mode: Lines + Markers for individual data points\n        name='Training Loss'  # Trace name\n    )\n)\n\n# Add a trace for validation loss values over epochs\nfig.add_trace(\n    go.Scatter(\n        x=list(range(len(val_loss_values))),  # X-axis: Epoch number\n        y=val_loss_values,  # Y-axis: Validation loss value\n        mode='lines+markers',  # Mode: Lines + Markers for individual data points\n        name='Validation Loss'  # Trace name\n    )\n)\n\n# Update the layout of the figure to include title and axis labels\nfig.update_layout(\n    title='Training and Validation Loss',  # Title of the plot\n    xaxis_title='Epoch',  # X-axis label\n    yaxis_title='Loss'  # Y-axis label\n)\n\n# Display the figure\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:29:51.978607Z","iopub.execute_input":"2023-10-01T15:29:51.979261Z","iopub.status.idle":"2023-10-01T15:29:52.240644Z","shell.execute_reply.started":"2023-10-01T15:29:51.979228Z","shell.execute_reply":"2023-10-01T15:29:52.239760Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"52cada1b-5f69-48ca-aa3a-a236d1a4c2ff\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"52cada1b-5f69-48ca-aa3a-a236d1a4c2ff\")) {                    Plotly.newPlot(                        \"52cada1b-5f69-48ca-aa3a-a236d1a4c2ff\",                        [{\"mode\":\"lines+markers\",\"name\":\"Training Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[1.323802836479679,1.0909522271925405,0.9164305906141956,0.7836073637008668,0.6575940097531964,0.5415472955473009,0.4501169641171733,0.3757027762551461,0.3192060262926163,0.2747543233056222,0.23999866602882264,0.21028878371561727,0.18831422828858896,0.1699003207106744,0.1572576244511912,0.14581310532746777],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Validation Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[1.1733330488204956,0.9795433282852173,0.833536684513092,0.707756519317627,0.5939728617668152,0.478120356798172,0.40251633524894714,0.32430678606033325,0.27750277519226074,0.24346713721752167,0.2115674614906311,0.1847567856311798,0.16338302195072174,0.1518900841474533,0.13859565556049347,0.12998317182064056],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Training and Validation Loss\"},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('52cada1b-5f69-48ca-aa3a-a236d1a4c2ff');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Predicting on Sample Texts\n\nIn this section, we create a function called predict_sample_texts to preprocess the provided text samples, run them through the model for predictions, and interpret the results to obtain human-readable labels. This function demonstrates how to use a pretrained transformer model and a classifier to predict on new data.","metadata":{}},{"cell_type":"code","source":"# Function to preprocess and predict on new text data\ndef predict_sample_texts(texts, model, classifier, tokenizer, device, threshold=0.7):\n    results = []  # List to store the results\n    \n    # Get the column headers except for the first one as a list\n    headers = df.columns.tolist()[1:]\n    \n    for text in texts:\n        # Step 1: Preprocess\n        # Tokenize the text and add special tokens\n        input_id = tokenizer.encode(text, add_special_tokens=True)\n        # Pad or truncate the token ids to a fixed length\n        input_id = pad_sequences([input_id], maxlen=128, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n        \n        # Create attention mask\n        attention_mask = [[float(i > 0) for i in seq] for seq in input_id]\n        \n        # Convert to PyTorch tensors and move to the given device\n        input_id = torch.tensor(input_id).to(device)\n        attention_mask = torch.tensor(attention_mask).to(device)\n        \n        # Step 2: Model Prediction\n        # Set the model and classifier to evaluation mode\n        model.eval()\n        classifier.eval()\n        \n        # No gradient computation to save memory\n        with torch.no_grad():\n            # Obtain model outputs\n            output = model(input_id, attention_mask=attention_mask)\n            logits_from_model = output.logits\n            logits = classifier(logits_from_model)\n            # Convert logits to probabilities\n            probabilities = torch.sigmoid(logits).cpu().numpy()\n            \n        # Step 3: Interpret the Result\n        # Binarize probabilities based on the threshold\n        binary_output = (probabilities >= threshold).astype(int)\n        \n        # Store the result in a dictionary and append to results list\n        results.append({\n            'text': text,\n            'probabilities': probabilities,\n            'binary_output': binary_output,\n            # Get the predicted labels\n            'predicted_labels': [label for label, output in zip(headers, binary_output[0]) if output == 1]\n        })\n        \n    return results  # Return the results list\n\n# Array of sample texts along with HPO terms for context\n# Headache (HP:0002315)\n# Dry skin (HP:0000958)\n# Nocturia (HP:0000017)\nsample_texts = [\n    \"Still thirsty, still constantly in the bathroom, and now I'm getting headaches that are making it tough to focus. Probably from all the lost fluids. Doctor says my sodium levels are still high. It's like my body's a malfunctioning tap.\",\n    \"I thought things couldn't get worse, but now my skin's as dry as the Sahara. Between this and everything else, I'm feeling pretty miserable.\",\n    \"Been waking up in the middle of the night to use the bathroom. It's affecting my sleep now, and I've started to feel groggy all day long.\"\n]\n\n# Get prediction\nresults = predict_sample_texts(sample_texts, model, classifier, tokenizer, device)\n\n# Output the results\nfor i, result in enumerate(results):\n    print(f\"Sample Text {i+1}: {result['text']}\")\n    print(f\"Predicted Labels: {result['predicted_labels']}\")\n    print(\"=\" * 50)  # Print a separator\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:30:24.725012Z","iopub.execute_input":"2023-10-01T15:30:24.725391Z","iopub.status.idle":"2023-10-01T15:30:24.775258Z","shell.execute_reply.started":"2023-10-01T15:30:24.725361Z","shell.execute_reply":"2023-10-01T15:30:24.774329Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Sample Text 1: Still thirsty, still constantly in the bathroom, and now I'm getting headaches that are making it tough to focus. Probably from all the lost fluids. Doctor says my sodium levels are still high. It's like my body's a malfunctioning tap.\nPredicted Labels: ['HP:0006959']\n==================================================\nSample Text 2: I thought things couldn't get worse, but now my skin's as dry as the Sahara. Between this and everything else, I'm feeling pretty miserable.\nPredicted Labels: []\n==================================================\nSample Text 3: Been waking up in the middle of the night to use the bathroom. It's affecting my sleep now, and I've started to feel groggy all day long.\nPredicted Labels: ['HP:0002451']\n==================================================\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Hyperparameter Tuning for BERT Sequence Classification\n\nIn this snippet, we define a training routine for a BERT-based sequence classification task. We utilize the hyperopt library to search for the optimal hyperparameters for training.","metadata":{}},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.optim import Adam, SGD, lr_scheduler\nimport torch\nimport numpy as np\nfrom hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n\n# Assume the definition of Focal Loss is available\n# from your_focal_loss import FocalLoss\n\n# Assume train_data, val_data, train_labels, n_neg, and n_pos are pre-defined TensorDatasets\n# They can also be passed as parameters if needed\n\ndef training_function(params):\n    # Extract parameters from the params dictionary\n    batch_size = params['batch_size']\n    learning_rate = params['lr']\n    num_epochs = params['num_epochs']\n    optimizer_type = params['optimizer']\n    step_size = params['step_size']\n    step_gamma = params['step_gamma']\n    \n    # Initialize metric storage\n    train_loss_values = []\n    val_loss_values = []\n    \n    # Initialize data loaders\n    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n    val_dataloader = DataLoader(val_data, batch_size=batch_size)\n    \n    # Initialize model\n    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=train_labels.shape[1])\n    classifier = torch.nn.Linear(train_labels.shape[1], train_labels.shape[1])\n\n    # Send model to device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    classifier.to(device)\n    \n    # Initialize optimizer and scheduler\n    if optimizer_type == 'adam':\n        optimizer = Adam(list(model.parameters()) + list(classifier.parameters()), lr=learning_rate)\n    else:\n        optimizer = SGD(list(model.parameters()) + list(classifier.parameters()), lr=learning_rate)\n    \n    scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=step_gamma)\n    \n    # Initialize loss function\n    pos_weights = (n_neg + 1e-5) / (n_pos + 1e-5)\n    pos_weights = torch.tensor(pos_weights).to(device)\n    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n    \n    # Training loop\n    for epoch in range(num_epochs):\n        model.train()\n        avg_train_loss = 0\n        avg_val_loss = 0\n        \n        for i, batch in enumerate(train_dataloader):\n            inputs, masks, labels = tuple(t.to(device) for t in batch)\n            labels = labels.float()  # Ensure labels are float if required\n            outputs = model(inputs, attention_mask=masks)\n            logits_from_model = outputs.logits\n            logits = classifier(logits_from_model)\n            loss = criterion(logits, labels)\n\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            avg_train_loss += loss.item() / len(train_dataloader)\n        \n        scheduler.step()\n        \n        # Validation loop\n        model.eval()\n        with torch.no_grad():\n            for batch in val_dataloader:\n                inputs, masks, labels = tuple(t.to(device) for t in batch)\n                labels = labels.float()  # Ensure labels are float if required\n                outputs = model(inputs, attention_mask=masks)\n                logits_from_model = outputs.logits\n                logits = classifier(logits_from_model)\n                loss = criterion(logits, labels)\n                \n                avg_val_loss += loss.item() / len(val_dataloader)\n                \n        train_loss_values.append(avg_train_loss)\n        val_loss_values.append(avg_val_loss)\n        \n    return {'loss': avg_val_loss, 'status': STATUS_OK}\n\n# Define the space of hyperparameters to search\nspace = {\n    'lr': hp.loguniform('lr', -7, 0),\n    'batch_size': hp.choice('batch_size', [8, 16, 32, 64]),\n    'num_epochs': hp.choice('num_epochs', [2, 5, 10]),\n    'step_size': hp.choice('step_size', [5, 10, 20]),\n    'step_gamma': hp.uniform('step_gamma', 0.5, 1),\n    'optimizer': hp.choice('optimizer', ['adam', 'sgd']),\n}\n\n# Objective function is the function to optimize\ntrials = Trials()\nbest = fmin(training_function,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=7,\n            trials=trials)\n\nprint(f\"Best hyperparameters: {best}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}